# Points to Ponder

Below are a few questions that are aimed at enhancing your understanding of week 2 's material. Try to think about possible reasons and then explore it online 
and discuss in the group for a clear understanding of the concepts.   

* Why Mean Squared Error is used in Linear Regression? Why not Absolute error or some other loss functions?

* What makes Learning Rate so powerful in determining the stability of the algorithm? Why is it called a hyper-parameter?

* What do you think is the advantage of Segemented Regression?

* Is Locally Weighted Regression good for tasks that have say a million training examples?

* Why is Locally Weighted Regression called 'Non - Parametric Learning' model?

* Why is Linear Regression not suitable for Classification problems in it's original form?

* Why do we choose sigmoid function in Logistic Regression? Why not some other functions? 

* Why do we use the log-loss (techincally called, cross-entropy loss) in Logistic Regression? Why not Mean Squared Error as in Linear Regression?
